# Bridging the Cultural Divide: SigLIP + DoRA for Indian Contexts

**Status:** Research Proposal (VLG Track)  
**Author:** Vedansh Singh Gautam  
**Focus:** Cultural Domain Adaptation, Parameter-Efficient Fine-Tuning (PEFT)

## ðŸ“Œ Overview
This project addresses the "Cultural Alignment Gap" in modern Vision-Language Models. While models like CLIP perform well globally, they struggle with region-specific concepts (e.g., distinguishing a *Sherwani* from a *Coat*).

We propose replacing standard approaches with a cutting-edge pipeline:
1.  **Architecture:** Google's **SigLIP** (Sigmoid Loss for Language Image Pre-Training) instead of the older CLIP.
2.  **Method:** **DoRA** (Weight-Decomposed LoRA) for robust fine-tuning without catastrophic forgetting.
3.  **Benchmark:** Introduction of **Indi-Bench**, a "Hard-Negative" evaluation set targeting high-confusion Indian cultural pairs.

## ðŸš€ Key Innovations
| Feature | Standard Approach | Our Approach |
| :--- | :--- | :--- |
| **Model** | CLIP (ViT-B/32) | **SigLIP (ViT-B/16)** |
| **Fine-Tuning** | Vanilla LoRA | **DoRA (Weight-Decomposed)** |
| **Evaluation** | General Accuracy | **Hard-Negative Cultural F1-Score** |

## ðŸ“‚ Repository Structure
```bash
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ indi_bench/       # The custom hard-negative test set
â”‚   â””â”€â”€ raw/              # Scripts to download DollarStreet/Food101 subsets
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py         # DoRA and SigLIP configuration
â”‚   â”œâ”€â”€ train.py          # Main training loop (HuggingFace PEFT)
â”‚   â””â”€â”€ eval.py           # Evaluation script for Indi-Bench
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_baseline.ipynb # Zero-shot inference demo
â””â”€â”€ README.md
